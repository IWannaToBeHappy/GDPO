python -m torch.distributed.run \
    --nproc_per_node 4 \
    --nnodes 1 \
    --node_rank 0 \
    /workspace/train.py \
    --model /workspace/model/deepseek-coder-1_3b-instruct \
    --model_type deepseek \
    --rlhf_type grpo \
    --train_type lora \
    --use_vllm true \
    --vllm_mode colocate \
    --vllm_gpu_memory_utilization 0.2 \
    --vllm_tensor_parallel_size 4 \
    --vllm_max_model_len 2048 \
    --dataset /workspace/dataset/train/starcoderdata_c_0.jsonl#10000 \
    --custom_dataset_info /workspace/dataset/dataset_info.json \
    --external_plugins /workspace/train/plugin.py \
    --reward_funcs external_reverse_geometric \
    --reward_funcs external_flesch_reading_ease external_reverse_geometric \
    --reward_weights 1 30 \
    --torch_dtype bfloat16 \
    --attn_impl flash_attn \
    --num_train_epochs 1 \
    --max_length 2048 \
    --max_completion_length 1024 \
    --truncation_strategy delete \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 8 \
    --num_generations 4 \
    --gradient_accumulation_steps 1 \
    --eval_steps 500 \
    --save_steps 500 \
    --learning_rate 1e-6 \
    --save_total_limit 2 \
    --logging_steps 5 \
    --output_dir /workspace/output/paper/geometric/deepseek-coder-1_3b-instruct-r2 \
    --warmup_ratio 0.05 \
    --dataloader_num_workers 4 \
    --temperature 1.1 \
    --top_p 1.0 \
    --top_k 80 \
    --log_completions true \
    --async_generate false \
    --offload_optimizer false \
    --offload_model false \
    --move_model_batches 40 \
    --sleep_level 0 \
    --overlong_filter true \
    --dynamic_sample false \
    --importance_sampling_level sequence \
    --system "You are a helpful assistant that generates code summaries. Given a piece of code, provide a concise summary." \